//! çœŸå®æ¨¡å‹ä¸‹è½½å’Œæµ‹è¯•ç¨‹åº
//!
//! è¿™ä¸ªç¤ºä¾‹ä¼šçœŸæ­£ä» Hugging Face ä¸‹è½½ potion-multilingual-128M æ¨¡å‹
//! å¹¶è¿›è¡Œå®é™…çš„æ–‡æœ¬åµŒå…¥ç”Ÿæˆæµ‹è¯•ã€‚

use model2vec_rs::model::StaticModel;
use std::time::Instant;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ AI00-Mem çœŸå®æ¨¡å‹ä¸‹è½½æµ‹è¯•");
    println!("æ­£åœ¨ä¸‹è½½ potion-multilingual-128M æ¨¡å‹...\n");

    let start_time = Instant::now();

    // å°è¯•å¤šä¸ªé•œåƒæºä¸‹è½½æ¨¡å‹
    println!("ğŸ“¥ å¼€å§‹ä»é•œåƒç«™ä¸‹è½½æ¨¡å‹...");

    // å°è¯•å¤šä¸ªé•œåƒæº
    let mirror_endpoints = vec![
        "https://hf-mirror.com",
        "https://huggingface.co",
        "https://hub.nuaa.cf",
        "https://hf.co",
    ];

    let mut model = None;
    for (i, endpoint) in mirror_endpoints.iter().enumerate() {
        println!("ğŸ”„ å°è¯•é•œåƒæº {}: {}", i + 1, endpoint);
        std::env::set_var("HF_ENDPOINT", endpoint);

        match StaticModel::from_pretrained(
            "minishlab/potion-multilingual-128M",
            None, // æ— éœ€ HF token
            None, // ä½¿ç”¨æ¨¡å‹é»˜è®¤çš„å½’ä¸€åŒ–è®¾ç½®
            None, // æ— å­æ–‡ä»¶å¤¹
        ) {
            Ok(m) => {
                println!("âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸï¼ä½¿ç”¨é•œåƒæº: {}", endpoint);
                model = Some(m);
                break;
            }
            Err(e) => {
                println!("âŒ é•œåƒæº {} å¤±è´¥: {}", endpoint, e);
                if i == mirror_endpoints.len() - 1 {
                    eprintln!("âŒ æ‰€æœ‰é•œåƒæºéƒ½å¤±è´¥äº†");
                    eprintln!("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•");
                    return Err(e.into());
                }
            }
        }
    }

    let model = model.unwrap();

    println!(
        "âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼æ€»è€—æ—¶: {:.2}ç§’",
        start_time.elapsed().as_secs_f32()
    );

    println!("\nğŸ§ª å¼€å§‹æµ‹è¯•æ–‡æœ¬åµŒå…¥ç”Ÿæˆ...");

    // æµ‹è¯•æ–‡æœ¬ï¼ˆä¸­è‹±æ–‡æ··åˆï¼‰
    let test_texts = vec![
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»æ•£æ­¥ã€‚",
        "æˆ‘æ­£åœ¨å­¦ä¹ äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ã€‚",
        "The weather is nice today, perfect for a walk.",
        "I am learning artificial intelligence and machine learning.",
        "äººå·¥æ™ºèƒ½å°†æ”¹å˜ä¸–ç•Œã€‚",
        "Machine learning is a subset of artificial intelligence.",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ã€‚",
        "Natural language processing enables computers to understand human language.",
    ];

    println!("\nğŸ“Š æµ‹è¯•ç»“æœ:");
    println!("{:-<80}", "");

    for (i, text) in test_texts.iter().enumerate() {
        let embedding_start = Instant::now();

        // ç”ŸæˆåµŒå…¥å‘é‡
        let sentences = vec![text.to_string()];
        let embeddings = model.encode(&sentences);

        let embedding_time = embedding_start.elapsed();

        if embeddings.is_empty() {
            println!("âŒ æµ‹è¯• {}: åµŒå…¥ç”Ÿæˆå¤±è´¥", i + 1);
            continue;
        }

        let embedding = &embeddings[0];

        // è®¡ç®—å‘é‡ç»Ÿè®¡ä¿¡æ¯
        let vector_norm = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        let mean = embedding.iter().sum::<f32>() / embedding.len() as f32;
        let variance =
            embedding.iter().map(|x| (x - mean).powi(2)).sum::<f32>() / embedding.len() as f32;

        println!("âœ… æµ‹è¯• {}: æˆåŠŸ", i + 1);
        println!("   æ–‡æœ¬: {}", text);
        println!("   å‘é‡ç»´åº¦: {}", embedding.len());
        println!("   ç”Ÿæˆè€—æ—¶: {:.2}ms", embedding_time.as_millis());
        println!("   å‘é‡èŒƒæ•°: {:.4}", vector_norm);
        println!("   å‡å€¼: {:.4}, æ–¹å·®: {:.4}", mean, variance);
        println!("   å‰5ä¸ªå€¼: {:?}", &embedding[..5.min(embedding.len())]);
        println!();
    }

    println!("{:-<80}", "");

    // æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼æ€§
    println!("\nğŸ” æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼æ€§è®¡ç®—...");

    let similar_pairs = vec![
        (
            "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºå»æ•£æ­¥ã€‚",
            "The weather is nice today, perfect for a walk.",
        ),
        (
            "æˆ‘æ­£åœ¨å­¦ä¹ äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ ã€‚",
            "I am learning artificial intelligence and machine learning.",
        ),
        (
            "äººå·¥æ™ºèƒ½å°†æ”¹å˜ä¸–ç•Œã€‚",
            "Machine learning is a subset of artificial intelligence.",
        ),
    ];

    for (text1, text2) in similar_pairs {
        let emb1 = &model.encode(&vec![text1.to_string()])[0];
        let emb2 = &model.encode(&vec![text2.to_string()])[0];

        // è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        let dot_product: f32 = emb1.iter().zip(emb2.iter()).map(|(a, b)| a * b).sum();
        let norm1: f32 = emb1.iter().map(|x| x * x).sum::<f32>().sqrt();
        let norm2: f32 = emb2.iter().map(|x| x * x).sum::<f32>().sqrt();
        let cosine_similarity = dot_product / (norm1 * norm2);

        println!("ğŸ“ æ–‡æœ¬å¯¹ç›¸ä¼¼åº¦: {:.4}", cosine_similarity);
        println!("   æ–‡æœ¬1: {}", text1);
        println!("   æ–‡æœ¬2: {}", text2);
        println!();
    }

    let total_time = start_time.elapsed();
    println!("ğŸ‰ æµ‹è¯•å®Œæˆï¼æ€»è€—æ—¶: {:.2}ç§’", total_time.as_secs_f32());

    println!("\nğŸ“‹ æµ‹è¯•æ€»ç»“:");
    println!("- âœ… æ¨¡å‹ä¸‹è½½: æˆåŠŸ");
    println!("- âœ… åµŒå…¥ç”Ÿæˆ: æˆåŠŸ");
    println!("- âœ… å¤šè¯­è¨€æ”¯æŒ: ä¸­æ–‡å’Œè‹±æ–‡éƒ½æ­£å¸¸å·¥ä½œ");
    println!("- âœ… è¯­ä¹‰ç›¸ä¼¼æ€§: è®¡ç®—æ­£å¸¸");
    println!("- ğŸ“Š å‘é‡ç»´åº¦: 256 (potion-multilingual-128M æ¨¡å‹é»˜è®¤)");
    println!("- âš¡ æ€§èƒ½: å•æ¬¡åµŒå…¥ç”Ÿæˆé€šå¸¸åœ¨å‡ æ¯«ç§’å†…å®Œæˆ");

    Ok(())
}
